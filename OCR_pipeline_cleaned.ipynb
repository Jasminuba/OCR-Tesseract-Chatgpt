{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fff97d0-6d2a-4f8a-9e58-4e78f5f4e820",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pymupdf pytesseract opencv-python pillow requests numpy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84117599-775d-4ea7-b586-0752ddae3604",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytesseract\n",
    "\n",
    "# Set the Tesseract path explicitly\n",
    "pytesseract.pytesseract.tesseract_cmd = r\"C:\\Program Files\\Tesseract-OCR\\tesseract.exe\"\n",
    "\n",
    "# Verify installation\n",
    "print(pytesseract.get_tesseract_version())  # This should print the Tesseract version\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f19cfb-b51e-4cb0-8a81-a05495fe1333",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import fitz\n",
    "from PIL import Image\n",
    "import io\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d1204e-6c3a-419e-b05a-46e431b1213a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import fitz  # PyMuPDF\n",
    "import requests\n",
    "from PIL import Image\n",
    "import io\n",
    "import pytesseract\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Set Tesseract OCR path for Windows\n",
    "pytesseract.pytesseract.tesseract_cmd = r\"C:\\Program Files\\Tesseract-OCR\\tesseract.exe\"\n",
    "\n",
    "# Ensure TESSDATA_PREFIX is correctly set\n",
    "os.environ[\"TESSDATA_PREFIX\"] = r\"C:\\Program Files\\Tesseract-OCR\\tessdata\"\n",
    "\n",
    "# Your OpenAI API Key\n",
    "API_KEY = os.getenv('OPENAI_API_KEY')\n",
    "# Define input and output folders\n",
    "pdf_folder = \"./input_pdfs\"\n",
    "output_folder = \"./OCR_results\"\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "def extract_page_as_image(pdf_path, page_index, resolution=900):\n",
    "    \"\"\"\n",
    "    Extracts a specific page from a PDF as an image.\n",
    "    \"\"\"\n",
    "    with fitz.open(pdf_path) as pdf:\n",
    "        if page_index < 0 or page_index >= pdf.page_count:\n",
    "            raise IndexError(\"Page index out of range.\")\n",
    "        \n",
    "        page = pdf[page_index]\n",
    "        zoom = resolution / 72  # Scaling factor\n",
    "        mat = fitz.Matrix(zoom, zoom)\n",
    "        pix = page.get_pixmap(matrix=mat)\n",
    "        img = Image.open(io.BytesIO(pix.tobytes(\"png\")))\n",
    "        return img\n",
    "\n",
    "def perform_ocr(image, language=\"slv\"):\n",
    "    \"\"\"\n",
    "    Performs OCR using Tesseract.\n",
    "    \"\"\"\n",
    "    return pytesseract.image_to_string(image, lang=language)\n",
    "\n",
    "def send_text_to_chatgpt(text, api_key):\n",
    "    \"\"\"\n",
    "    Sends OCR text to ChatGPT API for correction and enhancement.\n",
    "    \"\"\"\n",
    "    headers = {\n",
    "        'Authorization': f'Bearer {api_key}',\n",
    "        'Content-Type': 'application/json'\n",
    "    }\n",
    "\n",
    "    ocr_correction_prompt = f\"\"\"Correct OCR-induced errors in the text written in Slovene language (a historical text). Follow these guidelines:\n",
    "1. Fix OCR-induced typos and errors:\n",
    "   - Correct words split across line breaks\n",
    "   - Remove unnecessary line breaks within sentences or paragraphs to ensure smooth reading flow.\n",
    "   - Preserve meaningful paragraph breaks as they appear in the text.\n",
    "   - Combine fragmented lines into full sentences where appropriate.\n",
    "   - Fix common OCR errors (e.g., 'rn' misread as 'm')\n",
    "   - Use context and linguistic knowledge to fix errors, but do not make speculative changes.\n",
    "   - Focus only on clear errors; do not modify valid content unnecessarily.\n",
    "   - Do not add extra periods or any unnecessary punctuation unless required by grammatical correctness.\n",
    "\n",
    "2. Maintain original structure:\n",
    "   - Preserve all headings, subheadings, and their formatting.\n",
    "   - Do not merge or split paragraphs unless required to fix clear formatting issues caused by OCR.\n",
    "\n",
    "3. Preserve original content:\n",
    "   - Keep all important information from the original text unchanged.\n",
    "   - Do not add, infer, or introduce any new information.\n",
    "   \n",
    "4. Maintain coherence:\n",
    "   - Handle incomplete sentences gracefully: Correct partial sentences to make them grammatically and contextually correct and Resolve any disruptions caused by OCR errors that may fragment sentences or ideas.\n",
    "\n",
    "IMPORTANT: Respond ONLY with the corrected text. Preserve all original formatting, including line breaks, except where fixing unnecessary line breaks within sentences or paragraphs. Do not include any introduction, explanation, or metadata.\n",
    "\n",
    "Original Text in Slovene:\n",
    "{text}\"\"\"\n",
    "    \n",
    "    data = {\n",
    "        \"model\": \"gpt-4o\",\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": \"You are an expert in correcting OCR errors in typewriter texts.\"},\n",
    "            {\"role\": \"user\", \"content\": ocr_correction_prompt}\n",
    "        ]\n",
    "    }\n",
    "    response = requests.post(\"https://api.openai.com/v1/chat/completions\", headers=headers, json=data)\n",
    "    response.raise_for_status()\n",
    "    return response.json()['choices'][0]['message']['content']\n",
    "\n",
    "def process_pdf(pdf_path):\n",
    "    \"\"\"\n",
    "    Process all pages of a PDF file.\n",
    "    \"\"\"\n",
    "    filename = os.path.basename(pdf_path).rsplit('.', 1)[0]\n",
    "    raw_output_path = os.path.join(output_folder, f\"{filename}_raw.txt\")\n",
    "    corrected_output_path = os.path.join(output_folder, f\"{filename}_corrected.txt\")\n",
    "    \n",
    "    combined_raw_text = \"\"\n",
    "    combined_corrected_text = \"\"\n",
    "    \n",
    "    with fitz.open(pdf_path) as pdf:\n",
    "        num_pages = pdf.page_count\n",
    "        \n",
    "        for page_index in range(num_pages):\n",
    "            print(f\"Processing page {page_index + 1}/{num_pages} of {filename}...\")\n",
    "            try:\n",
    "                image = extract_page_as_image(pdf_path, page_index)\n",
    "                ocr_text = perform_ocr(image)\n",
    "                corrected_text = send_text_to_chatgpt(ocr_text, API_KEY)\n",
    "                \n",
    "                combined_raw_text += f\"\\n\\n=== Page {page_index + 1} ===\\n\\n{ocr_text}\"\n",
    "                combined_corrected_text += f\"\\n\\n=== Page {page_index + 1} ===\\n\\n{corrected_text}\"\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing page {page_index + 1}: {e}\")\n",
    "    \n",
    "    with open(raw_output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(combined_raw_text)\n",
    "    \n",
    "    with open(corrected_output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(combined_corrected_text)\n",
    "    \n",
    "    print(f\"Processing complete. Results saved in {output_folder}.\")\n",
    "\n",
    "# Process all PDFs in the folder\n",
    "pdf_files = [f for f in os.listdir(pdf_folder) if f.endswith(\".pdf\")]\n",
    "\n",
    "for pdf_file in pdf_files:\n",
    "    pdf_path = os.path.join(pdf_folder, pdf_file)\n",
    "    process_pdf(pdf_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c78aa83d-0d98-475c-9be6-ca160d76c896",
   "metadata": {},
   "source": [
    "## Evaluation â€“ WER and CER Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c61ebaa-77e1-4da6-b918-aaa3036f283e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# install modules\n",
    "!pip install -q jiwer matplotlib seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "066e3000",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from jiwer import wer, cer\n",
    "import pandas as pd\n",
    "\n",
    "# Define paths\n",
    "directory = 'OCR_results'\n",
    "\n",
    "# Initialize lists to store results\n",
    "documents = []\n",
    "wer_scores = []\n",
    "cer_scores = []\n",
    "\n",
    "unique_file_names = set()\n",
    "# Iterate over files\n",
    "for filename in os.listdir(directory):\n",
    "    unique_file_names.add(filename.replace('_raw', '').replace('_corrected', ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c12317",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over files\n",
    "for filename in unique_file_names:\n",
    "    name, ext = os.path.splitext(filename)\n",
    "    raw_filename = f\"{name}_raw{ext}\"\n",
    "    raw_path = os.path.join(directory, raw_filename)\n",
    "    corrected_filename = f\"{name}_corrected{ext}\"\n",
    "    corrected_path = os.path.join(directory, corrected_filename)\n",
    "    \n",
    "    # Read files\n",
    "    with open(raw_path, 'r', encoding='utf-8') as f:\n",
    "        raw_text = f.read()\n",
    "    with open(corrected_path, 'r', encoding='utf-8') as f:\n",
    "        corrected_text = f.read()\n",
    "    \n",
    "    # Compute WER and CER\n",
    "    wer_score = wer(corrected_text, raw_text)\n",
    "    cer_score = cer(corrected_text, raw_text)\n",
    "    \n",
    "    # Store results\n",
    "    documents.append(filename)\n",
    "    wer_scores.append(wer_score)\n",
    "    cer_scores.append(cer_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d328f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'Document': documents,\n",
    "    'WER': wer_scores,\n",
    "    'CER': cer_scores\n",
    "})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d1551fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d07e5be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results to CSV\n",
    "df.to_csv('ocr_evaluation_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef6f113b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort and plot WER per document\n",
    "df_sorted_wer = df.sort_values(by='WER', ascending=False)\n",
    "\n",
    "plt.figure(figsize=(10, 50))\n",
    "sns.barplot(y='Document', x='WER', data=df_sorted_wer)\n",
    "plt.title('Word Error Rate (WER) per Document (Sorted Descending)')\n",
    "plt.tight_layout()\n",
    "plt.savefig('wer_per_document.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe1c2d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Top 20\n",
    "df_sorted_wer = df.sort_values(by='WER', ascending=False)[:20]\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.barplot(y='Document', x='WER', data=df_sorted_wer)\n",
    "plt.title('Word Error Rate (WER) per Document (Top 20 Most Error Rate)')\n",
    "plt.tight_layout()\n",
    "plt.savefig('wer_per_document_top_20.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c471ba32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Bottom 20\n",
    "df_sorted_wer = df.sort_values(by='WER', ascending=True)[:20]\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.barplot(y='Document', x='WER', data=df_sorted_wer)\n",
    "plt.title('Word Error Rate (WER) per Document (Top 20 Least Error Rate)')\n",
    "plt.tight_layout()\n",
    "plt.savefig('wer_per_document_bottom_20.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a089687",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort and plot CER per document\n",
    "df_sorted_cer = df.sort_values(by='CER', ascending=False)\n",
    "\n",
    "plt.figure(figsize=(10, 50))\n",
    "sns.barplot(y='Document', x='CER', data=df_sorted_cer)\n",
    "plt.title('Character Error Rate (CER) per Document (Sorted Descending)')\n",
    "plt.tight_layout()\n",
    "plt.savefig('cer_per_document.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c5cc72e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Top 20\n",
    "df_sorted_cer = df.sort_values(by='CER', ascending=False)[:20]\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.barplot(y='Document', x='CER', data=df_sorted_cer)\n",
    "plt.title('Character Error Rate (CER) per Document (Top 20 Most Error Rate)')\n",
    "plt.tight_layout()\n",
    "plt.savefig('cer_per_document_top_20.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b683231e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Bottom 20\n",
    "df_sorted_cer = df.sort_values(by='CER', ascending=True)[:20]\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.barplot(y='Document', x='CER', data=df_sorted_cer)\n",
    "plt.title('Character Error Rate (CER) per Document (Top 20 Least Error Rate)')\n",
    "plt.tight_layout()\n",
    "plt.savefig('cer_per_document_bottom_20.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85f5236d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create side-by-side subplots\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# Plot WER histogram\n",
    "sns.histplot(data=df, x=\"WER\", kde=True, bins=30, color='skyblue', ax=axes[0])\n",
    "axes[0].set_title(\"Distribution of Word Error Rate (WER)\")\n",
    "axes[0].set_xlabel(\"WER\")\n",
    "axes[0].set_ylabel(\"Frequency\")\n",
    "\n",
    "# Plot CER histogram\n",
    "sns.histplot(data=df, x=\"CER\", kde=True, bins=30, color='salmon', ax=axes[1])\n",
    "axes[1].set_title(\"Distribution of Character Error Rate (CER)\")\n",
    "axes[1].set_xlabel(\"CER\")\n",
    "axes[1].set_ylabel(\"Frequency\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71f2c0a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "for metric in [\"WER\", \"CER\"]:\n",
    "    sorted_vals = np.sort(df[metric])\n",
    "    cdf = np.arange(len(sorted_vals)) / float(len(sorted_vals))\n",
    "    plt.plot(sorted_vals, cdf, label=metric)\n",
    "\n",
    "plt.title(\"Cumulative Distribution of WER and CER\")\n",
    "plt.xlabel(\"Error Rate\")\n",
    "plt.ylabel(\"Cumulative Proportion\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c0e991",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
